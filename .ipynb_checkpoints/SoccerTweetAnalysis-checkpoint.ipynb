{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "# Import and create a new SQLContext \n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form a country table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the country CSV file into an RDD.\n",
    "country_lines = sc.textFile('datasets/country-list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan, AFG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_lines.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each line into a pair of words\n",
    "words = country_lines.map(lambda line : line.split(\", \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Afghanistan', 'AFG'],\n",
       " ['Albania', 'ALB'],\n",
       " ['Algeria', 'ALG'],\n",
       " ['American Samoa', 'ASA']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each pair of words into a tuple\n",
    "country_tuples = words.map(lambda pair : (pair[0], pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Afghanistan', 'AFG'),\n",
       " ('Albania', 'ALB'),\n",
       " ('Algeria', 'ALG'),\n",
       " ('American Samoa', 'ASA')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_tuples.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', code='AFG'),\n",
       " Row(country='Albania', code='ALB'),\n",
       " Row(country='Algeria', code='ALG')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame, look at schema and contents\n",
    "countryDF = sqlContext.createDataFrame(country_tuples, [\"country\", \"code\"])\n",
    "countryDF.printSchema()\n",
    "countryDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the whole tweet text into word tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tweets CSV file into RDD of lines\n",
    "users = sc.textFile('datasets/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jsonDF = sqlContext.read.json(users.map(lambda r: r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- $oid: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- tweet_ID: string (nullable = true)\n",
      " |-- tweet_followers_count: long (nullable = true)\n",
      " |-- tweet_mentioned_count: long (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- CreatedAt: struct (nullable = true)\n",
      " |    |    |-- $date: string (nullable = true)\n",
      " |    |-- FavouritesCount: long (nullable = true)\n",
      " |    |-- FollowersCount: long (nullable = true)\n",
      " |    |-- FriendsCount: long (nullable = true)\n",
      " |    |-- Location: string (nullable = true)\n",
      " |    |-- UserId: long (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#json_schema = jsonDF.schema\n",
    "jsonDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11188 10\n"
     ]
    }
   ],
   "source": [
    "print(jsonDF.count(), len(jsonDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RT @ochocinco: I beat them all for 10 straight hours #FIFA16KING  https://t.co/BFnV6jfkBL'],\n",
       " ['RT @NiallOfficial: @Louis_Tomlinson @socceraid when I retired from playing because of my knee . I went and did my uefa A badges in Dublin'],\n",
       " ['RT @GameSeek: Follow & Retweet for your chance to win a copy of FIFA 17 Deluxe Edition (platform of your choice) in our #giveaway! https://…']]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/35457927/pyspark-convert-dataframe-to-rddstring\n",
    "test = jsonDF.select('tweet_text').rdd.map(list)\n",
    "test.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @ochocinco: I beat them all for 10 straight hours #FIFA16KING  https://t.co/BFnV6jfkBL',\n",
       " 'RT @NiallOfficial: @Louis_Tomlinson @socceraid when I retired from playing because of my knee . I went and did my uefa A badges in Dublin',\n",
       " 'RT @GameSeek: Follow & Retweet for your chance to win a copy of FIFA 17 Deluxe Edition (platform of your choice) in our #giveaway! https://…']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = jsonDF.select('tweet_text').rdd.flatMap(list)\n",
    "test.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @ochocinco: I beat them all for 10 straight hours #FIFA16KING  https://t.co/BFnV6jfkBL',\n",
       " 'RT @NiallOfficial: @Louis_Tomlinson @socceraid when I retired from playing because of my knee . I went and did my uefa A badges in Dublin',\n",
       " 'RT @GameSeek: Follow & Retweet for your chance to win a copy of FIFA 17 Deluxe Edition (platform of your choice) in our #giveaway! https://…']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tweet_strings = jsonDF.select('tweet_text').rdd.flatMap(list)\n",
    "list_of_tweet_strings.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11188"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tweet_strings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11188"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the data: some tweets are empty. Remove the empty tweets using filter() \n",
    "# IT APPEARS THERE IS NOTHING TO CLEAN!\n",
    "\n",
    "# jsonDF_filtered = jsonDF.filter(jsonDF.tweet_text.isNotNull())   might need to use jsonDF['tweet_text']\n",
    "# print(jsonDF_filtered.count(), len(jsonDF_filtered.columns))\n",
    "list_of_tweet_strings.filter(lambda line : len(line.strip()) > 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform WordCount on the cleaned tweet texts. (note: this is several lines.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT', '@ochocinco:', 'I']"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tweet_word_strings = list_of_tweet_strings.flatMap(lambda line : line.split(\" \"))\n",
    "list_of_tweet_word_strings.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', 1), ('@ochocinco:', 1), ('I', 1)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_tweet_word_tuples = list_of_tweet_word_strings.map(lambda word : (word, 1))\n",
    "list_of_tweet_word_tuples.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beat', 51), ('them', 70), ('10', 115)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_word_count = list_of_tweet_word_tuples.reduceByKey(lambda a, b: (a + b))\n",
    "tweet_word_count.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(word='beat', count=51),\n",
       " Row(word='them', count=70),\n",
       " Row(word='10', count=115)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the DataFrame of tweet word counts\n",
    "tweet_word_count_DF = sqlContext.createDataFrame(tweet_word_count, [\"word\", \"count\"])\n",
    "tweet_word_count_DF.printSchema()\n",
    "tweet_word_count_DF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the word tuple dataframe with the country dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Anguilla', code='AIA', word=None, count=None),\n",
       " Row(country='Malaysia', code='MAS', word=None, count=None),\n",
       " Row(country='Malawi', code='MWI', word=None, count=None),\n",
       " Row(country='Afghanistan', code='AFG', word=None, count=None),\n",
       " Row(country='Maldives', code='MDV', word=None, count=None),\n",
       " Row(country='Algeria', code='ALG', word=None, count=None),\n",
       " Row(country='Macau', code='MAC', word=None, count=None),\n",
       " Row(country='Argentina', code='ARG', word='Argentina', count=3),\n",
       " Row(country='Angola', code='ANG', word=None, count=None),\n",
       " Row(country='Albania', code='ALB', word='Albania', count=1)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the country and tweet data frames (on the appropriate column)\n",
    "joined = countryDF.join(tweet_word_count_DF, countryDF.country == tweet_word_count_DF.word, \"left_outer\")\n",
    "joined.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 1: number of distinct countries mentioned\n",
    "joined_filtered = joined.filter(joined['count'].isNotNull())\n",
    "joined_filtered.take(3)\n",
    "joined_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[393]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 2: number of countries mentioned in tweets.\n",
    "from pyspark.sql.functions import sum\n",
    "joined_filtered.groupby().sum().rdd.map(lambda x: x[0]).collect() \n",
    "#The \"rdd.map(lambda x: x[0]).collect()\" part is here just to help return a number instead of the number in a df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Norway', code='NOR', word='Norway', count=52),\n",
       " Row(country='Nigeria', code='NGA', word='Nigeria', count=50),\n",
       " Row(country='France', code='FRA', word='France', count=45)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 1: top three countries and their counts.\n",
    "from pyspark.sql.functions import desc\n",
    "joined_filtered_sorted = joined_filtered.sort(desc('count'))\n",
    "joined_filtered_sorted.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Iceland', code='ISL', word='Iceland', count=2),\n",
       " Row(country='Kenya', code='KEN', word='Kenya', count=3),\n",
       " Row(country='Netherlands', code='NED', word='Netherlands', count=13)]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 2: Which country was mentioned most: Kenya, Wales, or Netherlands?\n",
    "three_country_DF = joined_filtered.filter(joined_filtered['country'].isin(['Kenya','Iceland','Netherlands']))\n",
    "three_country_DF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
